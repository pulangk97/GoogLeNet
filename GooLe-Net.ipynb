{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a415ed64",
   "metadata": {},
   "source": [
    "批量归一化：防止梯度消失做得数值稳定方案\n",
    "用于输出的激活函数前或输入前\n",
    "沿着特征维或卷积通道维做归一化（批量归一化）\n",
    "最初是认为减小了模型内部协变量偏移\n",
    "后续发现不是，而是认为通过样品的均值方差加入了噪声，控制了模型复杂度\n",
    "能够加快收敛，但是不影响模型精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3c3c476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8cdb606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b314876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b8950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24685e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93077a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b58a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd8ad5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c17e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a237b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b521e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9042bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformCom=trans.Compose([trans.Resize(96),trans.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c026390",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet=torchvision.datasets.FashionMNIST('../',train=True,download=True,transform=transformCom)\n",
    "testSet=torchvision.datasets.FashionMNIST('../',train=False,download=True,transform=transformCom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55467df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader=data.DataLoader(trainSet,batch_size=128,shuffle=True)\n",
    "testLoader=data.DataLoader(testSet,batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d7ac7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_channels, c1, c2, c3, c4, **kwargs):\n",
    "        super(Inception, self).__init__(**kwargs)\n",
    "        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
    "        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n",
    "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
    "        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)\n",
    "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
    "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        p1 = self.relu(self.p1_1(x))\n",
    "        p2 = self.relu(self.p2_2(self.relu(self.p2_1(x))))\n",
    "        p3 = self.relu(self.p3_2(self.relu(self.p3_1(x))))\n",
    "        p4 = self.relu(self.p4_2(self.p4_1(x)))\n",
    "        return torch.cat((p1, p2, p3, p4), dim=1)\n",
    "        \n",
    "#GoogLe-Net网络，relu激活\n",
    "b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2,padding=1))\n",
    "\n",
    "b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1), nn.ReLU(),\n",
    "                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),\n",
    "                   Inception(256, 128, (128, 192), (32, 96), 64),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n",
    "                   Inception(512, 160, (112, 224), (24, 64), 64),\n",
    "                   Inception(512, 128, (128, 256), (24, 64), 64),\n",
    "                   Inception(512, 112, (144, 288), (32, 64), 64),\n",
    "                   Inception(528, 256, (160, 320), (32, 128), 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n",
    "                   Inception(832, 384, (192, 384), (48, 128), 128),\n",
    "                   nn.AdaptiveAvgPool2d((1,1)), nn.Flatten())\n",
    "\n",
    "GoogLeNet = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04bb8512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 24, 24])\n",
      "Sequential output shape:\t torch.Size([1, 192, 12, 12])\n",
      "Sequential output shape:\t torch.Size([1, 480, 6, 6])\n",
      "Sequential output shape:\t torch.Size([1, 832, 3, 3])\n",
      "Sequential output shape:\t torch.Size([1, 1024])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 1, 96, 96))\n",
    "for layer in GoogLeNet:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ee53b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04adc06b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Inception(\n",
       "      (p1_1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p2_1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p2_2): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (p3_1): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p3_2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (p4_2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Inception(\n",
       "      (p1_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p2_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p2_2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (p3_1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p3_2): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (p4_2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Inception(\n",
       "      (p1_1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p2_1): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p2_2): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (p3_1): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p3_2): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (p4_2): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Inception(\n",
       "      (p1_1): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p2_1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p2_2): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (p3_1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p3_2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Inception(\n",
       "      (p1_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p2_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p2_2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (p3_1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p3_2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Inception(\n",
       "      (p1_1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p2_1): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p2_2): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (p3_1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p3_2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): Inception(\n",
       "      (p1_1): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p2_1): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p2_2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (p3_1): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p3_2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (p4_2): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): Inception(\n",
       "      (p1_1): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p2_1): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p2_2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (p3_1): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p3_2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (p4_2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Inception(\n",
       "      (p1_1): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p2_1): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p2_2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (p3_1): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (p3_2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (p4_2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (3): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (5): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GoogLeNet.to(torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aade71f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim=torch.optim.SGD(GoogLeNet.parameters(),lr=0.1)\n",
    "loss=torch.nn.CrossEntropyLoss()\n",
    "loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d3bbe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr, num_epochs, batch_size = 0.1, 10, 128\n",
    "# train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
    "# d2l.train_ch6(GoogLeNet, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42f9dcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.9666845 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.       ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6005/1906723072.py:62: UserWarning: Attempting to set identical left == right == 0 results in singular transformations; automatically expanding.\n",
      "  ax.set_xlim(0, max(xdata))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.9666845 1.8212733 0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.       ]\n",
      "[1.9666845 1.8212733 1.6025636 0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.       ]\n",
      "[1.9666845 1.8212733 1.6025636 1.5026474 0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.       ]\n",
      "[1.9666845 1.8212733 1.6025636 1.5026474 1.7259643 0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.       ]\n",
      "[1.9666845 1.8212733 1.6025636 1.5026474 1.7259643 1.7607405 0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.       ]\n",
      "[1.9666845 1.8212733 1.6025636 1.5026474 1.7259643 1.7607405 1.3976755\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.       ]\n",
      "[1.9666845 1.8212733 1.6025636 1.5026474 1.7259643 1.7607405 1.3976755\n",
      " 1.6419091 0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.       ]\n",
      "[1.9666845 1.8212733 1.6025636 1.5026474 1.7259643 1.7607405 1.3976755\n",
      " 1.6419091 1.5237567 0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.       ]\n",
      "[1.9666845 1.8212733 1.6025636 1.5026474 1.7259643 1.7607405 1.3976755\n",
      " 1.6419091 1.5237567 1.5464908 0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.       ]\n",
      "[1.9666845 1.8212733 1.6025636 1.5026474 1.7259643 1.7607405 1.3976755\n",
      " 1.6419091 1.5237567 1.5464908 1.455234  0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.       ]\n",
      "[1.9666845 1.8212733 1.6025636 1.5026474 1.7259643 1.7607405 1.3976755\n",
      " 1.6419091 1.5237567 1.5464908 1.455234  1.4532745 0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.       ]\n",
      "[1.9666845 1.8212733 1.6025636 1.5026474 1.7259643 1.7607405 1.3976755\n",
      " 1.6419091 1.5237567 1.5464908 1.455234  1.4532745 1.3576068 0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.       ]\n",
      "[1.9666845 1.8212733 1.6025636 1.5026474 1.7259643 1.7607405 1.3976755\n",
      " 1.6419091 1.5237567 1.5464908 1.455234  1.4532745 1.3576068 1.407548\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.       ]\n",
      "[1.9666845 1.8212733 1.6025636 1.5026474 1.7259643 1.7607405 1.3976755\n",
      " 1.6419091 1.5237567 1.5464908 1.455234  1.4532745 1.3576068 1.407548\n",
      " 1.5035955 0.        0.        0.        0.        0.        0.\n",
      " 0.       ]\n",
      "[1.9666845 1.8212733 1.6025636 1.5026474 1.7259643 1.7607405 1.3976755\n",
      " 1.6419091 1.5237567 1.5464908 1.455234  1.4532745 1.3576068 1.407548\n",
      " 1.5035955 1.6874696 0.        0.        0.        0.        0.\n",
      " 0.       ]\n",
      "[1.9666845 1.8212733 1.6025636 1.5026474 1.7259643 1.7607405 1.3976755\n",
      " 1.6419091 1.5237567 1.5464908 1.455234  1.4532745 1.3576068 1.407548\n",
      " 1.5035955 1.6874696 1.5856631 0.        0.        0.        0.\n",
      " 0.       ]\n",
      "[1.9666845 1.8212733 1.6025636 1.5026474 1.7259643 1.7607405 1.3976755\n",
      " 1.6419091 1.5237567 1.5464908 1.455234  1.4532745 1.3576068 1.407548\n",
      " 1.5035955 1.6874696 1.5856631 1.6940846 0.        0.        0.\n",
      " 0.       ]\n",
      "[1.9666845 1.8212733 1.6025636 1.5026474 1.7259643 1.7607405 1.3976755\n",
      " 1.6419091 1.5237567 1.5464908 1.455234  1.4532745 1.3576068 1.407548\n",
      " 1.5035955 1.6874696 1.5856631 1.6940846 1.4280005 0.        0.\n",
      " 0.       ]\n",
      "[1.9666845 1.8212733 1.6025636 1.5026474 1.7259643 1.7607405 1.3976755\n",
      " 1.6419091 1.5237567 1.5464908 1.455234  1.4532745 1.3576068 1.407548\n",
      " 1.5035955 1.6874696 1.5856631 1.6940846 1.4280005 1.4336114 0.\n",
      " 0.       ]\n",
      "[1.9666845 1.8212733 1.6025636 1.5026474 1.7259643 1.7607405 1.3976755\n",
      " 1.6419091 1.5237567 1.5464908 1.455234  1.4532745 1.3576068 1.407548\n",
      " 1.5035955 1.6874696 1.5856631 1.6940846 1.4280005 1.4336114 1.4189719\n",
      " 0.       ]\n"
     ]
    }
   ],
   "source": [
    "#创建曲线图并初始化\n",
    "xdata=[]\n",
    "ydata=[]\n",
    "xdataTest=[]\n",
    "ydataTest=[]\n",
    "fig, ax = pyp.subplots()\n",
    "line, = ax.plot(xdata, ydata,color='blue')\n",
    "line2, = ax.plot(xdataTest, ydataTest,color='red')\n",
    "pyp.title(\"Loss\")\n",
    "pyp.xlabel(\"epoch\")\n",
    "pyp.ylabel(\"Loss\")\n",
    "pyp.grid()\n",
    "ax.legend((line,line2),('trainLoss','testLoss'))\n",
    "#动态更新曲线训练函数\n",
    "num_epoch=22\n",
    "aveLoss=torch.zeros(num_epoch)\n",
    "aveLoss=aveLoss.detach().numpy()\n",
    "aveLossTest=torch.zeros(num_epoch)\n",
    "# aveLossTest=aveLoss.detach().numpy()\n",
    "def animationTrain(epoch):\n",
    "    #每epoch训练代码区#\n",
    "    #初始化参数为均匀分布，教训：初始化参数对训练是否收敛影响巨大，初始化为0完全不收敛\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    GoogLeNet.apply(init_weights)\n",
    "    sumLoss=0\n",
    "    trainnum=0;\n",
    "    if epoch>0:\n",
    "        for trainData,trainLabel in trainLoader:\n",
    "            optim.zero_grad()\n",
    "            Y=trainLabel.to(torch.device(\"cuda:0\"))\n",
    "            X=trainData.to(torch.device(\"cuda:0\"))\n",
    "            YHAT=GoogLeNet(X)\n",
    "            comLoss=loss(YHAT,Y)\n",
    "            comLoss.backward()\n",
    "            optim.step()\n",
    "            sumLoss=comLoss+sumLoss\n",
    "            trainnum=trainnum+1\n",
    "        aveLoss[epoch-1]=(sumLoss.to(torch.device(\"cpu\"))/trainnum)\n",
    "        sumLoss=0\n",
    "        trainnum=0\n",
    "        with torch.no_grad():\n",
    "            for trainData,trainLabel in testLoader:\n",
    "                Y=trainLabel.to(torch.device(\"cuda:0\"))\n",
    "                X=trainData.to(torch.device(\"cuda:0\"))\n",
    "                YHAT=GoogLeNet(X)\n",
    "                comLoss=loss(YHAT,Y)\n",
    "                sumLoss=comLoss+sumLoss\n",
    "                trainnum=trainnum+1\n",
    "        aveLossTest[epoch-1]=(sumLoss.to(torch.device(\"cpu\"))/trainnum)   \n",
    "        print(aveLoss)\n",
    "        #图表数据更新#\n",
    "        xdata.append(epoch-1)\n",
    "        ydata.append(aveLoss[epoch-1])\n",
    "        xdataTest.append(epoch-1)\n",
    "        ydataTest.append(aveLossTest[epoch-1])\n",
    "        line.set_xdata(xdata)\n",
    "        line.set_ydata(ydata)\n",
    "        line2.set_xdata(xdataTest)\n",
    "        line2.set_ydata(ydataTest)\n",
    "        ax.set_xlim(0, max(xdata))\n",
    "        ax.set_ylim(0, max(ydata))\n",
    "        #print(aveLoss[epoch])\n",
    "        return line,line2,\n",
    "#创建动画对象并显示，显示过程逐次调用Trian函数\n",
    "anim = animation.FuncAnimation(fig, animationTrain, interval=20, blit=False,repeat=False,frames=num_epoch)\n",
    "pyp.show()     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c61b15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
